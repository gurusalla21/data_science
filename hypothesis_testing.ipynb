{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "[Hypothesis testing](#Hypothesis)<br/>\n",
    "[Power Calculation](#Power)<br/>\n",
    "[Experiment Design](#Experiment)<br/>\n",
    "[Z-test](#Z)<br/>\n",
    "[T-test](#T)<br/>\n",
    "[A/B testing](#AB)<br/>\n",
    "[Bias Variance](#BV)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Hypothesis'></a>\n",
    "### Hypothesis Testing\n",
    "\n",
    "- State null hypothesis $H_0$ (typically status quo, no effect)\n",
    "- Choose a significance level $\\alpha$\n",
    "- Choose and compute appropriate test statistics\n",
    "- Compute p-value and 'reject' or 'fail to reject' $H_0$\n",
    "\n",
    "**Type I error** - $\\alpha$, reject $H_0$ when it is true (convict innocent)<br/>\n",
    "**Type II error** - $\\beta$, fail to reject $H_0$ when it is false (release guilty)\n",
    "\n",
    "<img src=\"img/hypothesis_testing.png\" width=\"300\">\n",
    "\n",
    "|              |             | Actual                    |                          |\n",
    "|--------------|-------------|---------------------------|--------------------------|\n",
    "|              |             | $H_0$ true                | $H_0$ false              |\n",
    "|**Predicted** | $H_0$ true  | Correct / TN / 1-$\\alpha$ | Type II / FN / $\\beta$   | *fail to reject $H_0$*\n",
    "|              | $H_0$ false | Type I / FP / $\\alpha$    | Correct / TP / 1-$\\beta$ | *reject $H_0$*\n",
    "\n",
    "**One-sample vs Two-sample Tests**\n",
    "\n",
    "Two-sample:\n",
    "- Two sets of observations to compare - usually from A/B testing\n",
    "- The question is whether given statistic is better/different for one set of observations; is click through rate on landing page A better than on landing page B given these observations?\n",
    "\n",
    "One-sample:\n",
    "- Only one set of observations is available - compare it against specific statistic value\n",
    "- We have 23 observations telling us the click through rate is 0.217; can we say our overall click through rate is at least 0.2?\n",
    "\n",
    "**One-sided vs Two-sided Tests**\n",
    "\n",
    "Two-sided:\n",
    "- Reject $H_0$ if test statistic is in upper or lower tail\n",
    "- Compute p-value using probability of being in either tail\n",
    "\n",
    "One-sided:\n",
    "- Reject $H_0$ if test statistic is in the wrong tail (advertising does not decrease sales)\n",
    "- Compute p-value using probability of being in only one tail\n",
    "\n",
    "<a id='Power'></a>\n",
    "### Power Calculation\n",
    "\n",
    "**power** (sensitivity) - 1-$\\beta$, probability of not making type II error<br/>\n",
    "**significance** level (type I eror) - $\\alpha$, probability of rejecting $H_0$ given that it is true\n",
    "\n",
    "[statsmodels documentation](http://statsmodels.sourceforge.net/devel/stats.html#power-and-sample-size-calculations)\n",
    "\n",
    "- $N (N_T, N_C)$ - number of observation in treatment and control group\n",
    "- effect size: $\\theta_1 - \\theta_0$ (for example 1% for direct mail campaign)\n",
    "- standard deviation: $\\sigma (\\sigma_T, \\sigma_C)$ (p(1-p) for binomial distribution / click through rate)\n",
    "- significance: $\\alpha$ (good value is 0.05)\n",
    "- power: $1-\\beta$ (good value is 0.8)\n",
    "\n",
    "Provided four of the five information above, we can calculate the rest.\n",
    "\n",
    "Ideally we want:\n",
    "- $N_T = N_C$\n",
    "- big effect size\n",
    "- lots of data (bigger spikes in the image above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min sample size: 464.378743205\n",
      "min sample size: 465.734515503\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "from statsmodels.stats import power\n",
    "\n",
    "# this function was provided in class\n",
    "def calc_min_sample_size(std_dev, mean_desired, mean_original, alpha=0.05, power=0.8):\n",
    "    Z_alpha = st.norm.ppf(alpha)\n",
    "    Z_power = st.norm.ppf(power)\n",
    "\n",
    "    return ((Z_power - Z_alpha) * std_dev / (mean_desired - mean_original)) ** 2\n",
    "\n",
    "print 'min sample size: {}'.format(calc_min_sample_size(std_dev=2.6, mean_desired=7.35, \n",
    "                                                        mean_original=7.05, alpha=0.05, power=0.8))\n",
    "\n",
    "from statsmodels.stats.power import tt_solve_power # one sample t-test\n",
    "\n",
    "print 'min sample size: {}'.format(tt_solve_power(effect_size=(7.35-7.05)/2.6, nobs=None, alpha=0.05, \n",
    "                                                  power=0.8, alternative='larger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min sample in group 1: 1179.0732676\n",
      "min sample in group 1: 1180.03441727\n"
     ]
    }
   ],
   "source": [
    "# power calculation in statsmodels\n",
    "# whatever is set to None is calculated\n",
    "\n",
    "from statsmodels.stats.power import zt_ind_solve_power # two sample z-test\n",
    "\n",
    "print 'min sample in group 1: {}'.format(zt_ind_solve_power(effect_size=(7.35-7.05)/2.6, nobs1=None, \n",
    "                                                            alpha=0.05, power=0.8, ratio=1, alternative='two-sided'))\n",
    "\n",
    "from statsmodels.stats.power import tt_ind_solve_power # two sample t-test\n",
    "\n",
    "print 'min sample in group 1: {}'.format(tt_ind_solve_power(effect_size=(7.35-7.05)/2.6, nobs1=None,\n",
    "                                                            alpha=0.05, power=0.8, ratio=1, alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval\n",
    "\n",
    "*If we compute CI from multiple random samples from population, then 95% will contain the true population value.*\n",
    "\n",
    "- $CI^{(1-\\alpha)}$ .. confidence interval<br/>\n",
    "- $\\alpha$ .. significance level<br/>\n",
    "- $CI^{95} => \\alpha = 0.05$\n",
    "\n",
    "$Prob[truevalue \\notin CI^{(1-\\alpha)}] \\le \\alpha$ \n",
    "\n",
    "### P-value\n",
    "\n",
    "*Probability of observing data which is at least as extreme as what was observed assuming the $H_0$ is true.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Experiment'></a>\n",
    "### Experiment Design\n",
    "\n",
    "Rubin causal model\n",
    "\n",
    "Classical Random Experiment Assumptions:\n",
    "\n",
    "1. Individualistic - assignment of person A to treatment not affected bz assignment of person B\n",
    "- Probabilistic - everyone has non-zero probability of being assigned to each group\n",
    "- Unconfounded - assignment is independent on outcomes\n",
    "- Known assignment to treatment\n",
    "- SUTVA - same treatment for everyone (stable unit treatment value assumption)\n",
    "\n",
    "Without point 4 the data is **observational**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refresher:\n",
    "- $\\sigma^2$ .. variance\n",
    "- $\\sigma$ .. standard deviation\n",
    "- $\\sigma / \\sqrt{N}$ .. standard error\n",
    "- $\\mu$ .. mean / average\n",
    "\n",
    "<a id='Z'></a>\n",
    "### Z-test\n",
    "\n",
    "*Use when variance is known.*\n",
    "\n",
    "$z = \\frac {(\\overline{x} - \\mu)} {\\frac {\\sigma} {\\sqrt{N}}}$\n",
    "\n",
    "By definition, we know variance of Binomial distribution if we know p:\n",
    "- Prob(X) = p\n",
    "- Var = $\\sigma^2$ = ${p(1-p)}$\n",
    "- In cases like click through rate z-test is appropriate: $z = \\frac {\\mu_1 - \\mu_2} {\\sqrt{\\frac {p_1(1-p_1)} {N_1} + \\frac {p_2(1-p_2)} {N_2}}}$\n",
    "\n",
    "To compare means (assuming they are independent) with the same standard deviation `statsmodels.ztest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddof = 0\n",
      "my z-test result: 0.594088525786\n",
      "statsmodels z-test result: 0.594088525786\n",
      "\n",
      "ddof = 1\n",
      "my z-test result: 0.542326144547\n",
      "statsmodels z-test result: 0.542326144547\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "A = np.array([0,1,1,1,0,1])\n",
    "B = np.array([0,1,1,0,0,1])\n",
    "pA = A.mean()\n",
    "pB = B.mean()\n",
    "effect = A.mean() - B.mean()\n",
    "\n",
    "error = np.sqrt( ((pA*(1-pA))/len(A)) + ((pB*(1-pB))/len(B)) )\n",
    "z = effect / error\n",
    "\n",
    "print 'ddof = 0'\n",
    "print 'my z-test result: {}'.format(z) # 0.594\n",
    "print 'statsmodels z-test result: {}'.format(ztest(A, B, alternative='two-sided', ddof=0)[0]) # 0.594\n",
    "\n",
    "error = np.sqrt( ((pA*(1-pA))/(len(A)-1)) + ((pB*(1-pB))/(len(B)-1)) )\n",
    "z = effect / error\n",
    "\n",
    "print '\\nddof = 1' # default in statsmodels\n",
    "print 'my z-test result: {}'.format(z) # 0.542\n",
    "print 'statsmodels z-test result: {}'.format(ztest(A, B, alternative='two-sided', ddof=1)[0]) # 0.542"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels z-test has three alternatives:\n",
    "- two sided: the result is **p**\n",
    "- smaller: one-sided, the result is **p/2**\n",
    "- larger: one sided, the result is **1-(p/2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('z-statistic', -1.0954451150103321), ('p-value', 0.27332167829229814)]\n",
      "[('z-statistic', -1.0954451150103321), ('p-value', 0.13666083914614907)]\n",
      "[('z-statistic', -1.0954451150103321), ('p-value', 0.86333916085385098)]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "print zip(('z-statistic', 'p-value'), ztest([2,3,4,5], [3,4,5,6], alternative='two-sided'))\n",
    "print zip(('z-statistic', 'p-value'), ztest([2,3,4,5], [3,4,5,6], alternative='smaller'))\n",
    "print zip(('z-statistic', 'p-value'), ztest([2,3,4,5], [3,4,5,6], alternative='larger'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare means from distributions with different standard deviation use `CompareMeans.ztest_ind`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('z-statistic', -1.0954451150103321), ('p-value', 0.27332167829229814)]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import CompareMeans, DescrStatsW\n",
    "\n",
    "cm = CompareMeans(DescrStatsW([2,3,4,5]), DescrStatsW([3,4,5,6]))\n",
    "print zip(('z-statistic', 'p-value'), cm.ztest_ind(alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='T'></a>\n",
    "## T-test\n",
    "\n",
    "*Use when variance is unknown.*\n",
    "\n",
    "$t = \\frac {(\\overline{x} - \\mu)} {\\frac {S} {\\sqrt{N}}}$\n",
    "\n",
    "Used for anything continuous like amount of money spent.\n",
    "\n",
    "Calculate the T-test for the means of two independent samples of scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.36514837167011088, pvalue=0.72450697149417942)\n",
      "Ttest_indResult(statistic=-0.36514837167011083, pvalue=0.72446582573474294)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "print ttest_ind([0,0,1,0,2], [0,1,1,0,2], equal_var=False) # Welch’s t-test (do not assume equal population variance)\n",
    "print ttest_ind([0,0,1,0,2], [0,1,1,0,2], equal_var=True)  # standard independent 2 sample t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='AB'></a>\n",
    "### A/B Testing\n",
    "\n",
    "Can we say if one of the landing pages is better (i.e. gets more registrations) than the other with statistical significance?\n",
    "\n",
    "|                 | Visitors  | Registrations |\n",
    "|-----------------|-----------|---------------|\n",
    "| Landing Page A  | 1,012     | 349           |\n",
    "| Landing Page B  |   995     | 320           |\n",
    "\n",
    "- $H_0$: Landing pages A and B are the same.\n",
    "- $H_1$: One of the pages is better.\n",
    "\n",
    "Visit > register ratio\n",
    "- Landing Page A: 349 / 1,012 = 0.3448\n",
    "- Landing Page B: 320 / 995 = 0.3216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('z-statistic', 1.1046903609737513), ('p-value', 0.26929378150307026)]\n",
      "[('z-statistic', 1.1046903609737513), ('p-value', 0.13464689075153513)]\n"
     ]
    }
   ],
   "source": [
    "# create data: visit without registering 0, visit and register 1\n",
    "lpA = np.zeros(1012)\n",
    "lpA[0:349] = 1\n",
    "lpB = np.zeros(995)\n",
    "lpB[0:320] = 1\n",
    "\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "print zip(('z-statistic', 'p-value'), ztest(lpA, lpB, alternative='two-sided'))\n",
    "print zip(('z-statistic', 'p-value'), ztest(lpA, lpB, alternative='larger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.269200758683 0.134600379342\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency([[349, 1012-349], [320, 995-320]], correction=False)\n",
    "print p, p/2\n",
    "\n",
    "# do we need to Yates contiuity correction here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='BV'></a>\n",
    "### Bias-variance Tradeoff\n",
    "\n",
    "Bias and Variance cannot actually be calculated!\n",
    "- Bias = underfitting\n",
    "- Variance = overfitting\n",
    "\n",
    "$ Bias = E[\\hat{f}(x)] - f(x) $ ... model prediction - truth\n",
    "\n",
    "$ Variance = E[ (\\hat{f}(x) - E[\\hat{f}(x)])^{2} ] $\n",
    "\n",
    "$ MSE = Bias^{2} + ModelVariance + \\sigma_\\epsilon^{2} $ ... sigma is irreducible error\n",
    "\n",
    "- Inference is possible with low (almost zero) bias.\n",
    "- Gauss–Markov theorem: OLS is BLUE = ordinary least square estimator is best linear unbiased estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
